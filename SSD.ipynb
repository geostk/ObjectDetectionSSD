{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from layers import *\n",
    "from data import v2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SSD(nn.Module):\n",
    "    \"\"\"Single Shot Multibox Architecture\n",
    "    The network is composed of a base VGG network followed by the\n",
    "    added multibox conv layers.  Each multibox layer branches into\n",
    "        1) conv2d for class conf scores\n",
    "        2) conv2d for localization predictions\n",
    "        3) associated priorbox layer to produce default bounding\n",
    "           boxes specific to the layer's feature map size.\n",
    "    See: https://arxiv.org/pdf/1512.02325.pdf for more details.\n",
    "\n",
    "    Args:\n",
    "        phase: (string) Can be \"test\" or \"train\"\n",
    "        base: VGG16 layers for input, size of either 300 or 500\n",
    "        extras: extra layers that feed to multibox loc and conf layers\n",
    "        head: \"multibox head\" consists of loc and conf conv layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, phase, base, extras, head, num_classes):\n",
    "        super(SSD, self).__init__()\n",
    "        self.phase = phase\n",
    "        self.num_classes = num_classes\n",
    "        # TODO: implement __call__ in PriorBox\n",
    "        self.priorbox = PriorBox(v2)\n",
    "        self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
    "        self.size = 300\n",
    "\n",
    "        # SSD network\n",
    "        self.vgg = nn.ModuleList(base)\n",
    "        # Layer learns to scale the l2 normalized features from conv4_3\n",
    "        self.L2Norm = L2Norm(512, 20)\n",
    "        self.extras = nn.ModuleList(extras)\n",
    "\n",
    "        self.loc = nn.ModuleList(head[0])\n",
    "        self.conf = nn.ModuleList(head[1])\n",
    "\n",
    "        if phase == 'test':\n",
    "            self.softmax = nn.Softmax()\n",
    "            self.detect = Detect(num_classes, 0, 200, 0.01, 0.45)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies network layers and ops on input image(s) x.\n",
    "\n",
    "        Args:\n",
    "            x: input image or batch of images. Shape: [batch,3*batch,300,300].\n",
    "\n",
    "        Return:\n",
    "            Depending on phase:\n",
    "            test:\n",
    "                Variable(tensor) of output class label predictions,\n",
    "                confidence score, and corresponding location predictions for\n",
    "                each object detected. Shape: [batch,topk,7]\n",
    "\n",
    "            train:\n",
    "                list of concat outputs from:\n",
    "                    1: confidence layers, Shape: [batch*num_priors,num_classes]\n",
    "                    2: localization layers, Shape: [batch,num_priors*4]\n",
    "                    3: priorbox layers, Shape: [2,num_priors*4]\n",
    "        \"\"\"\n",
    "        sources = list()\n",
    "        loc = list()\n",
    "        conf = list()\n",
    "\n",
    "        # apply vgg up to conv4_3 relu\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "\n",
    "        s = self.L2Norm(x)\n",
    "        sources.append(s)\n",
    "\n",
    "        # apply vgg up to fc7\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        sources.append(x)\n",
    "\n",
    "        # apply extra layers and cache source layer outputs\n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inplace=True)\n",
    "            if k % 2 == 1:\n",
    "                sources.append(x)\n",
    "\n",
    "        # apply multibox head to source layers\n",
    "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "        if self.phase == \"test\":\n",
    "            output = self.detect(\n",
    "                loc.view(loc.size(0), -1, 4),                   # loc preds\n",
    "                self.softmax(conf.view(-1, self.num_classes)),  # conf preds\n",
    "                self.priors.type(type(x.data))                  # default boxes\n",
    "            )\n",
    "        else:\n",
    "            output = (\n",
    "                loc.view(loc.size(0), -1, 4),\n",
    "                conf.view(conf.size(0), -1, self.num_classes),\n",
    "                self.priors\n",
    "            )\n",
    "        return output\n",
    "\n",
    "    def load_weights(self, base_file):\n",
    "        other, ext = os.path.splitext(base_file)\n",
    "        if ext == '.pkl' or '.pth':\n",
    "            print('Loading weights into state dict...')\n",
    "            self.load_state_dict(torch.load(base_file, map_location=lambda storage, loc: storage))\n",
    "            print('Finished!')\n",
    "        else:\n",
    "            print('Sorry only .pth and .pkl files supported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg(cfg, i, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = i\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        elif v == 'C':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "    conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)\n",
    "    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "    layers += [pool5, conv6,\n",
    "               nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_extras(cfg, i, batch_norm=False):\n",
    "    # Extra layers added to VGG for feature scaling\n",
    "    layers = []\n",
    "    in_channels = i\n",
    "    flag = False\n",
    "    for k, v in enumerate(cfg):\n",
    "        if in_channels != 'S':\n",
    "            if v == 'S':\n",
    "                layers += [nn.Conv2d(in_channels, cfg[k + 1],\n",
    "                           kernel_size=(1, 3)[flag], stride=2, padding=1)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, v, kernel_size=(1, 3)[flag])]\n",
    "            flag = not flag\n",
    "        in_channels = v\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multibox(vgg, extra_layers, cfg, num_classes):\n",
    "    loc_layers = []\n",
    "    conf_layers = []\n",
    "    vgg_source = [24, -2]\n",
    "    for k, v in enumerate(vgg_source):\n",
    "        loc_layers += [nn.Conv2d(vgg[v].out_channels,\n",
    "                                 cfg[k] * 4, kernel_size=3, padding=1)]\n",
    "        conf_layers += [nn.Conv2d(vgg[v].out_channels,\n",
    "                        cfg[k] * num_classes, kernel_size=3, padding=1)]\n",
    "    for k, v in enumerate(extra_layers[1::2], 2):\n",
    "        loc_layers += [nn.Conv2d(v.out_channels, cfg[k]\n",
    "                                 * 4, kernel_size=3, padding=1)]\n",
    "        conf_layers += [nn.Conv2d(v.out_channels, cfg[k]\n",
    "                                  * num_classes, kernel_size=3, padding=1)]\n",
    "    return vgg, extra_layers, (loc_layers, conf_layers)\n",
    "\n",
    "\n",
    "base = {\n",
    "    '300': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M',\n",
    "            512, 512, 512],\n",
    "    '512': [],\n",
    "}\n",
    "extras = {\n",
    "    '300': [256, 'S', 512, 128, 'S', 256, 128, 256, 128, 256],\n",
    "    '512': [],\n",
    "}\n",
    "mbox = {\n",
    "    '300': [4, 6, 6, 6, 4, 4],  # number of boxes per feature map location\n",
    "    '512': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_ssd(phase, size=300, num_classes=21):\n",
    "    if phase != \"test\" and phase != \"train\":\n",
    "        print(\"Error: Phase not recognized\")\n",
    "        return\n",
    "    if size != 300:\n",
    "        print(\"Error: Sorry only SSD300 is supported currently!\")\n",
    "        return\n",
    "\n",
    "    return SSD(phase, *multibox(vgg(base[str(size)], 3),\n",
    "                                add_extras(extras[str(size)], 1024),\n",
    "                                mbox[str(size)], num_classes), num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:virtual_platform]",
   "language": "python",
   "name": "conda-env-virtual_platform-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
